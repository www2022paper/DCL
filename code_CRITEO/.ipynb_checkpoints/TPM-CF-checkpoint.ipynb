{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5253fb-8c45-4439-9d6f-320a6ba5cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 16:41:29.513342: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-24 16:41:29.559679: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-24 16:41:29.559703: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-24 16:41:29.559741: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-24 16:41:29.568435: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-24 16:41:30.542427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "CPU times: user 2.77 s, sys: 2.34 s, total: 5.12 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_loss(history, *losses):\n",
    "    for loss in losses:\n",
    "        plt.plot(history.history[loss], label=loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def scaling(x, min, max):\n",
    "    return np.where(x < min, 0.0, np.where(x > max, 1.0, (x - min) / (max - min)))\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # \n",
    "    patience=500,        # \n",
    "    verbose=1,          # \n",
    "    mode='min',         # \n",
    "    restore_best_weights=True  # \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71a2eef-9d0f-42af-8791-a15b3970e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"../data\"\n",
    "file_criteo = SAVE_DIR + \"/criteo-uplift-v2.1.csv\"\n",
    "df_criteo_ori = pd.read_csv(file_criteo, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39b4166-6354-4734-9c7b-02ca19d6be46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>treatment</th>\n",
       "      <th>conversion</th>\n",
       "      <th>visit</th>\n",
       "      <th>exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "      <td>1.397959e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.962030e+01</td>\n",
       "      <td>1.006998e+01</td>\n",
       "      <td>8.446582e+00</td>\n",
       "      <td>4.178923e+00</td>\n",
       "      <td>1.033884e+01</td>\n",
       "      <td>4.028513e+00</td>\n",
       "      <td>-4.155356e+00</td>\n",
       "      <td>5.101765e+00</td>\n",
       "      <td>3.933581e+00</td>\n",
       "      <td>1.602764e+01</td>\n",
       "      <td>5.333396e+00</td>\n",
       "      <td>-1.709672e-01</td>\n",
       "      <td>8.500001e-01</td>\n",
       "      <td>2.916680e-03</td>\n",
       "      <td>4.699200e-02</td>\n",
       "      <td>3.063122e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.377464e+00</td>\n",
       "      <td>1.047557e-01</td>\n",
       "      <td>2.993161e-01</td>\n",
       "      <td>1.336645e+00</td>\n",
       "      <td>3.433081e-01</td>\n",
       "      <td>4.310974e-01</td>\n",
       "      <td>4.577914e+00</td>\n",
       "      <td>1.205248e+00</td>\n",
       "      <td>5.665958e-02</td>\n",
       "      <td>7.018975e+00</td>\n",
       "      <td>1.682288e-01</td>\n",
       "      <td>2.283277e-02</td>\n",
       "      <td>3.570713e-01</td>\n",
       "      <td>5.392748e-02</td>\n",
       "      <td>2.116217e-01</td>\n",
       "      <td>1.723164e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.261636e+01</td>\n",
       "      <td>1.005965e+01</td>\n",
       "      <td>8.214383e+00</td>\n",
       "      <td>-8.398387e+00</td>\n",
       "      <td>1.028053e+01</td>\n",
       "      <td>-9.011892e+00</td>\n",
       "      <td>-3.142978e+01</td>\n",
       "      <td>4.833815e+00</td>\n",
       "      <td>3.635107e+00</td>\n",
       "      <td>1.319006e+01</td>\n",
       "      <td>5.300375e+00</td>\n",
       "      <td>-1.383941e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.261636e+01</td>\n",
       "      <td>1.005965e+01</td>\n",
       "      <td>8.214383e+00</td>\n",
       "      <td>4.679882e+00</td>\n",
       "      <td>1.028053e+01</td>\n",
       "      <td>4.115453e+00</td>\n",
       "      <td>-6.699321e+00</td>\n",
       "      <td>4.833815e+00</td>\n",
       "      <td>3.910792e+00</td>\n",
       "      <td>1.319006e+01</td>\n",
       "      <td>5.300375e+00</td>\n",
       "      <td>-1.686792e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.192341e+01</td>\n",
       "      <td>1.005965e+01</td>\n",
       "      <td>8.214383e+00</td>\n",
       "      <td>4.679882e+00</td>\n",
       "      <td>1.028053e+01</td>\n",
       "      <td>4.115453e+00</td>\n",
       "      <td>-2.411115e+00</td>\n",
       "      <td>4.833815e+00</td>\n",
       "      <td>3.971858e+00</td>\n",
       "      <td>1.319006e+01</td>\n",
       "      <td>5.300375e+00</td>\n",
       "      <td>-1.686792e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.443646e+01</td>\n",
       "      <td>1.005965e+01</td>\n",
       "      <td>8.723335e+00</td>\n",
       "      <td>4.679882e+00</td>\n",
       "      <td>1.028053e+01</td>\n",
       "      <td>4.115453e+00</td>\n",
       "      <td>2.944427e-01</td>\n",
       "      <td>4.833815e+00</td>\n",
       "      <td>3.971858e+00</td>\n",
       "      <td>1.319006e+01</td>\n",
       "      <td>5.300375e+00</td>\n",
       "      <td>-1.686792e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.674526e+01</td>\n",
       "      <td>1.634419e+01</td>\n",
       "      <td>9.051962e+00</td>\n",
       "      <td>4.679882e+00</td>\n",
       "      <td>2.112351e+01</td>\n",
       "      <td>4.115453e+00</td>\n",
       "      <td>2.944427e-01</td>\n",
       "      <td>1.199840e+01</td>\n",
       "      <td>3.971858e+00</td>\n",
       "      <td>7.529502e+01</td>\n",
       "      <td>6.473917e+00</td>\n",
       "      <td>-1.686792e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 f0            f1            f2            f3            f4  \\\n",
       "count  1.397959e+07  1.397959e+07  1.397959e+07  1.397959e+07  1.397959e+07   \n",
       "mean   1.962030e+01  1.006998e+01  8.446582e+00  4.178923e+00  1.033884e+01   \n",
       "std    5.377464e+00  1.047557e-01  2.993161e-01  1.336645e+00  3.433081e-01   \n",
       "min    1.261636e+01  1.005965e+01  8.214383e+00 -8.398387e+00  1.028053e+01   \n",
       "25%    1.261636e+01  1.005965e+01  8.214383e+00  4.679882e+00  1.028053e+01   \n",
       "50%    2.192341e+01  1.005965e+01  8.214383e+00  4.679882e+00  1.028053e+01   \n",
       "75%    2.443646e+01  1.005965e+01  8.723335e+00  4.679882e+00  1.028053e+01   \n",
       "max    2.674526e+01  1.634419e+01  9.051962e+00  4.679882e+00  2.112351e+01   \n",
       "\n",
       "                 f5            f6            f7            f8            f9  \\\n",
       "count  1.397959e+07  1.397959e+07  1.397959e+07  1.397959e+07  1.397959e+07   \n",
       "mean   4.028513e+00 -4.155356e+00  5.101765e+00  3.933581e+00  1.602764e+01   \n",
       "std    4.310974e-01  4.577914e+00  1.205248e+00  5.665958e-02  7.018975e+00   \n",
       "min   -9.011892e+00 -3.142978e+01  4.833815e+00  3.635107e+00  1.319006e+01   \n",
       "25%    4.115453e+00 -6.699321e+00  4.833815e+00  3.910792e+00  1.319006e+01   \n",
       "50%    4.115453e+00 -2.411115e+00  4.833815e+00  3.971858e+00  1.319006e+01   \n",
       "75%    4.115453e+00  2.944427e-01  4.833815e+00  3.971858e+00  1.319006e+01   \n",
       "max    4.115453e+00  2.944427e-01  1.199840e+01  3.971858e+00  7.529502e+01   \n",
       "\n",
       "                f10           f11     treatment    conversion         visit  \\\n",
       "count  1.397959e+07  1.397959e+07  1.397959e+07  1.397959e+07  1.397959e+07   \n",
       "mean   5.333396e+00 -1.709672e-01  8.500001e-01  2.916680e-03  4.699200e-02   \n",
       "std    1.682288e-01  2.283277e-02  3.570713e-01  5.392748e-02  2.116217e-01   \n",
       "min    5.300375e+00 -1.383941e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    5.300375e+00 -1.686792e-01  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    5.300375e+00 -1.686792e-01  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    5.300375e+00 -1.686792e-01  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    6.473917e+00 -1.686792e-01  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "           exposure  \n",
       "count  1.397959e+07  \n",
       "mean   3.063122e-02  \n",
       "std    1.723164e-01  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.000000e+00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_criteo_ori.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ede53c9-b837-48dc-bc0f-440d9b223bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9785714 (9785714, 12) (3494899, 12) 13979592 (698979, 12)\n",
      "CPU times: user 5.84 s, sys: 1.84 s, total: 7.69 s\n",
      "Wall time: 7.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample = 1.0\n",
    "random_state=20220720\n",
    "df_criteo=df_criteo_ori.sample(frac=sample, random_state=random_state).reset_index(drop=True)\n",
    "X = df_criteo[['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']].values\n",
    "\n",
    "X[:, 0] = scaling(X[:, 0], min=np.min(X[:, 0]), max=np.max(X[:, 0]))\n",
    "X[:, 1] = scaling(X[:, 1], min=np.min(X[:, 1]), max=np.max(X[:, 1]))\n",
    "X[:, 2] = scaling(X[:, 2], min=np.min(X[:, 2]), max=np.max(X[:, 2]))\n",
    "X[:, 3] = scaling(X[:, 3], min=np.min(X[:, 3]), max=np.max(X[:, 3]))\n",
    "X[:, 4] = scaling(X[:, 4], min=np.min(X[:, 4]), max=np.max(X[:, 4]))\n",
    "X[:, 5] = scaling(X[:, 5], min=np.min(X[:, 5]), max=np.max(X[:, 5]))\n",
    "X[:, 6] = scaling(X[:, 6], min=np.min(X[:, 6]), max=np.max(X[:, 6]))\n",
    "X[:, 7] = scaling(X[:, 7], min=np.min(X[:, 7]), max=np.max(X[:, 7]))\n",
    "X[:, 8] = scaling(X[:, 8], min=np.min(X[:, 8]), max=np.max(X[:, 8]))\n",
    "X[:, 9] = scaling(X[:, 9], min=np.min(X[:, 9]), max=np.max(X[:, 9]))\n",
    "X[:, 10] = scaling(X[:, 10], min=np.min(X[:, 10]), max=np.max(X[:, 10]))\n",
    "X[:, 11] = scaling(X[:, 11], min=np.min(X[:, 11]), max=np.max(X[:, 11]))\n",
    "\n",
    "T = df_criteo['treatment'].values.reshape(-1, 1)\n",
    "Y_visit = df_criteo['visit'].values.reshape(-1, 1)\n",
    "Y_conv = df_criteo['conversion'].values.reshape(-1, 1)\n",
    "\n",
    "T.shape, Y_visit.shape, Y_conv.shape\n",
    "\n",
    "\n",
    "# calculate len\n",
    "train_len = int(len(X) * 0.70)\n",
    "cali_len = int(len(X) * 0.05)\n",
    "test_len = len(X) - train_len - cali_len\n",
    "\n",
    "# obtain train set\n",
    "X_train = X[:train_len, :]\n",
    "T_train = T[:train_len, :]\n",
    "Y_visit_train = Y_visit[:train_len, :]\n",
    "Y_conv_train = Y_conv[:train_len, :]\n",
    "\n",
    "# obtain calibration set\n",
    "X_cali = X[train_len:train_len+cali_len, :]\n",
    "T_cali = T[train_len:train_len+cali_len, :]\n",
    "Y_visit_cali = Y_visit[train_len:train_len+cali_len, :]\n",
    "Y_conv_cali = Y_conv[train_len:train_len+cali_len, :]\n",
    "\n",
    "# obtain test set\n",
    "X_test = X[train_len+cali_len:, :]\n",
    "T_test = T[train_len+cali_len:, :]\n",
    "Y_visit_test = Y_visit[train_len+cali_len:, :]\n",
    "Y_conv_test = Y_conv[train_len+cali_len:, :]\n",
    "\n",
    "print(train_len, X_train.shape, X_test.shape, len(X), X_cali.shape)\n",
    "\n",
    "# make covariate shift\n",
    "# condition_cali = (X_cali[:, 0] > 0.3) & (X_cali[:, 1] < 0.7)\n",
    "# X_cali = X_cali[condition_cali]\n",
    "# T_cali = T_cali[condition_cali]\n",
    "# Y_visit_cali = Y_visit_cali[condition_cali]\n",
    "# Y_conv_cali = Y_conv_cali[condition_cali]\n",
    "\n",
    "# condition_test = (X_test[:, 0] > 0.3) & (X_test[:, 1] < 0.7)\n",
    "# X_test = X_test[condition_test]\n",
    "# T_test = T_test[condition_test]\n",
    "# Y_visit_test = Y_visit_test[condition_test]\n",
    "# Y_conv_test = Y_conv_test[condition_test]\n",
    "\n",
    "# print(train_len, X_train.shape, X_test.shape, len(X), X_cali.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe8bf7c-1761-4f6b-a074-429ca661a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72a2f03-d69f-42c9-ad03-449a53530e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store test aucc for pic \n",
    "import pandas as pd\n",
    "\n",
    "def get_aucc_cost_curve(aucc_list):\n",
    "    delta_cost_list_group = np.array([aucc[1] for aucc in aucc_list])\n",
    "    delta_reward_list_group = np.array([aucc[2] for aucc in aucc_list])\n",
    "    \n",
    "    avg_delta_cost_list = np.mean(delta_cost_list_group, axis=0)\n",
    "    avg_delta_reward_list = np.mean(delta_reward_list_group, axis=0)\n",
    "    \n",
    "    df_aucc_cost_curve = pd.DataFrame(avg_delta_cost_list, columns=['delta_cost'])\n",
    "    df_aucc_cost_curve['delta_reward'] = avg_delta_reward_list\n",
    "    \n",
    "    return df_aucc_cost_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64170305-cd6b-4a01-bbb4-b8f13047ccac",
   "metadata": {},
   "source": [
    "# TPM-CF method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ddeabd-ff6a-4782-af19-9bc0c8448dbc",
   "metadata": {},
   "source": [
    "### Train model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5529997a-b1f8-4cce-88ec-f3288e32481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.7034\n",
      "std = 0.0223\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from model.uplift_model import *\n",
    "\n",
    "from econml.dml import CausalForestDML\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "import pickle\n",
    "\n",
    "grf_aucc_list = []\n",
    "\n",
    "X_grf_train = X_train\n",
    "T_grf_train = T_train.flatten()\n",
    "Y_visit_grf_train = Y_visit_train.flatten()\n",
    "Y_conv_grf_train = Y_conv_train.flatten()\n",
    "\n",
    "X_grf_test = X_test\n",
    "T_grf_test = T_test.flatten()\n",
    "Y_visit_grf_test = Y_visit_test.flatten()\n",
    "Y_conv_grf_test = Y_conv_test.flatten()\n",
    "\n",
    "for i in range(count):\n",
    "    \n",
    "    \n",
    "    \n",
    "    depth = 16\n",
    "    min_samples_leaf = 100\n",
    "    n_estimators = 256\n",
    "\n",
    "    grf_random_state = 20220723 + i * 11\n",
    "    \n",
    "    # visit\n",
    "    est_it = CausalForestDML(model_y=RandomForestClassifier(n_estimators=160, max_samples = 0.7, random_state=grf_random_state, max_depth=12, min_samples_leaf=500, n_jobs=32),\n",
    "                          model_t=RandomForestClassifier(n_estimators=160, max_samples = 0.7, random_state=grf_random_state, max_depth=12, min_samples_leaf=500, n_jobs=32),\n",
    "                          discrete_treatment=True,\n",
    "                          cv=3,\n",
    "                          n_estimators=n_estimators,\n",
    "                          n_jobs=32,\n",
    "                          max_depth=depth,\n",
    "                          min_samples_leaf = min_samples_leaf,\n",
    "                          random_state=grf_random_state)\n",
    "\n",
    "    est_it.fit(Y_visit_grf_train, T_grf_train, X=X_grf_train, cache_values=True)\n",
    "    \n",
    "    model_file = \"../model_file/uplift/criteo/final_model/grf/A_visit_CausalForestDML_{}.model\".format(i + 1)\n",
    "    \n",
    "    fw = open(model_file, \"wb\")\n",
    "\n",
    "    pickle.dump(est_it, fw)\n",
    "\n",
    "    fw.close()\n",
    "    \n",
    "    grf_test_pre_visit = est_it.effect(X_grf_test)\n",
    "    \n",
    "    # conv\n",
    "    est_it = CausalForestDML(model_y=RandomForestClassifier(n_estimators=160, max_samples = 0.7, random_state=grf_random_state, max_depth=12, min_samples_leaf=500, n_jobs=32),\n",
    "                          model_t=RandomForestClassifier(n_estimators=160, max_samples = 0.7, random_state=grf_random_state, max_depth=12, min_samples_leaf=500, n_jobs=32),\n",
    "                          discrete_treatment=True,\n",
    "                          cv=3,\n",
    "                          n_estimators=n_estimators,\n",
    "                          n_jobs=32,\n",
    "                          max_depth=depth,\n",
    "                          min_samples_leaf = min_samples_leaf,\n",
    "                          random_state=grf_random_state)\n",
    "\n",
    "    est_it.fit(Y_conv_grf_train, T_grf_train, X=X_grf_train, cache_values=True)\n",
    "    \n",
    "    model_file = \"../model_file/uplift/criteo/final_model/grf/A_conv_CausalForestDML_{}.model\".format(i + 1)\n",
    "    \n",
    "    fw = open(model_file, \"wb\")\n",
    "\n",
    "    pickle.dump(est_it, fw)\n",
    "\n",
    "    fw.close()\n",
    "    \n",
    "    grf_test_pre_conv = est_it.effect(X_grf_test)\n",
    "    \n",
    "    # roi\n",
    "    \n",
    "    roi_grf_pre = grf_test_pre_conv / np.where(abs(grf_test_pre_visit) < 1e-6, 1e-6, grf_test_pre_visit)\n",
    "\n",
    "\n",
    "    grf_aucc = get_uplift_model_aucc(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=roi_grf_pre.flatten(), quantile=200)\n",
    "\n",
    "    grf_aucc_list.append(grf_aucc)\n",
    "\n",
    "mean_pred = np.mean(grf_aucc_list, axis=0)\n",
    "std_pred = np.std(grf_aucc_list, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"mean = {mean_pred:.4f}\")\n",
    "print(f\"std = {std_pred:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a6c201-8fba-4f2a-ad60-435a93a93c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

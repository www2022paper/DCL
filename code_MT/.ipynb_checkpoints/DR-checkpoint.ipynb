{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5253fb-8c45-4439-9d6f-320a6ba5cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 16:42:10.014495: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-24 16:42:10.061178: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-24 16:42:10.061206: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-24 16:42:10.061237: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-24 16:42:10.070191: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-24 16:42:11.041954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "CPU times: user 2.75 s, sys: 2.37 s, total: 5.12 s\n",
      "Wall time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_loss(history, *losses):\n",
    "    for loss in losses:\n",
    "        plt.plot(history.history[loss], label=loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def scaling(x, min, max):\n",
    "    return np.where(x < min, 0.0, np.where(x > max, 1.0, (x - min) / (max - min)))\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # \n",
    "    patience=500,        # \n",
    "    verbose=1,          # \n",
    "    mode='min',         # \n",
    "    restore_best_weights=True  # \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71a2eef-9d0f-42af-8791-a15b3970e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"../data\"\n",
    "file_criteo = SAVE_DIR + \"/MT-LIFT/train.csv\"\n",
    "df_criteo_ori = pd.read_csv(file_criteo, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ede53c9-b837-48dc-bc0f-440d9b223bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2041521 (2041521, 96) (729116, 96) 2916459 (145822, 96)\n",
      "CPU times: user 8.64 s, sys: 4.85 s, total: 13.5 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample = 1.0\n",
    "random_state=20220720\n",
    "df_criteo=df_criteo_ori[(df_criteo_ori['treatment'] == 0) | (df_criteo_ori['treatment'] == 3)].sample(frac=sample, random_state=random_state).reset_index(drop=True)\n",
    "# Change 'treatment' from 3 to 1 in df_criteo_ori\n",
    "df_criteo['treatment'] = df_criteo['treatment'].replace(3, 1)\n",
    "\n",
    "# X = df_criteo[['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']].values\n",
    "\n",
    "# X[:, 0] = scaling(X[:, 0], min=np.min(X[:, 0]), max=np.max(X[:, 0]))\n",
    "# X[:, 1] = scaling(X[:, 1], min=np.min(X[:, 1]), max=np.max(X[:, 1]))\n",
    "# X[:, 2] = scaling(X[:, 2], min=np.min(X[:, 2]), max=np.max(X[:, 2]))\n",
    "# X[:, 3] = scaling(X[:, 3], min=np.min(X[:, 3]), max=np.max(X[:, 3]))\n",
    "# X[:, 4] = scaling(X[:, 4], min=np.min(X[:, 4]), max=np.max(X[:, 4]))\n",
    "# X[:, 5] = scaling(X[:, 5], min=np.min(X[:, 5]), max=np.max(X[:, 5]))\n",
    "# X[:, 6] = scaling(X[:, 6], min=np.min(X[:, 6]), max=np.max(X[:, 6]))\n",
    "# X[:, 7] = scaling(X[:, 7], min=np.min(X[:, 7]), max=np.max(X[:, 7]))\n",
    "# X[:, 8] = scaling(X[:, 8], min=np.min(X[:, 8]), max=np.max(X[:, 8]))\n",
    "# X[:, 9] = scaling(X[:, 9], min=np.min(X[:, 9]), max=np.max(X[:, 9]))\n",
    "# X[:, 10] = scaling(X[:, 10], min=np.min(X[:, 10]), max=np.max(X[:, 10]))\n",
    "# X[:, 11] = scaling(X[:, 11], min=np.min(X[:, 11]), max=np.max(X[:, 11]))\n",
    "# # \n",
    "columns = [f'f{i}' for i in range(99) if not (80 <= i <= 82)] \n",
    "X = df_criteo[columns].values\n",
    "# \n",
    "for i in range(X.shape[1]):\n",
    "    # \n",
    "    if i not in [80, 81, 82]:\n",
    "        X[:, i] = scaling(X[:, i], min=np.min(X[:, i]), max=np.max(X[:, i]))\n",
    "\n",
    "T = df_criteo['treatment'].values.reshape(-1, 1)\n",
    "Y_visit = df_criteo['click'].values.reshape(-1, 1)\n",
    "Y_conv = df_criteo['conversion'].values.reshape(-1, 1)\n",
    "\n",
    "T.shape, Y_visit.shape, Y_conv.shape\n",
    "\n",
    "\n",
    "# calculate len\n",
    "train_len = int(len(X) * 0.70)\n",
    "cali_len = int(len(X) * 0.05)\n",
    "test_len = len(X) - train_len - cali_len\n",
    "\n",
    "# obtain train set\n",
    "X_train = X[:train_len, :]\n",
    "T_train = T[:train_len, :]\n",
    "Y_visit_train = Y_visit[:train_len, :]\n",
    "Y_conv_train = Y_conv[:train_len, :]\n",
    "\n",
    "# obtain calibration set\n",
    "X_cali = X[train_len:train_len+cali_len, :]\n",
    "T_cali = T[train_len:train_len+cali_len, :]\n",
    "Y_visit_cali = Y_visit[train_len:train_len+cali_len, :]\n",
    "Y_conv_cali = Y_conv[train_len:train_len+cali_len, :]\n",
    "\n",
    "# obtain test set\n",
    "X_test = X[train_len+cali_len:, :]\n",
    "T_test = T[train_len+cali_len:, :]\n",
    "Y_visit_test = Y_visit[train_len+cali_len:, :]\n",
    "Y_conv_test = Y_conv[train_len+cali_len:, :]\n",
    "\n",
    "print(train_len, X_train.shape, X_test.shape, len(X), X_cali.shape)\n",
    "\n",
    "# make covariate shift\n",
    "# condition_cali = (X_cali[:, 0] > 0.3) & (X_cali[:, 1] < 0.7)\n",
    "# X_cali = X_cali[condition_cali]\n",
    "# T_cali = T_cali[condition_cali]\n",
    "# Y_visit_cali = Y_visit_cali[condition_cali]\n",
    "# Y_conv_cali = Y_conv_cali[condition_cali]\n",
    "\n",
    "# condition_test = (X_test[:, 0] > 0.3) & (X_test[:, 1] < 0.7)\n",
    "# X_test = X_test[condition_test]\n",
    "# T_test = T_test[condition_test]\n",
    "# Y_visit_test = Y_visit_test[condition_test]\n",
    "# Y_conv_test = Y_conv_test[condition_test]\n",
    "\n",
    "# print(train_len, X_train.shape, X_test.shape, len(X), X_cali.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e46bfb-1c9e-47d3-805e-c3169fe3a117",
   "metadata": {},
   "source": [
    "# First, on the train set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b1270-59d6-415a-9aaf-0a7b4ef2417e",
   "metadata": {},
   "source": [
    "### (i) Train DR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c639e328-aeca-487e-aa7d-9978da14d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# DR on train set\n",
    "sys.path.append(\"..\")\n",
    "from model.uplift_model import *\n",
    "\n",
    "count = 20\n",
    "# 2.5e-5\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from model.roi_model import *\n",
    "\n",
    "# DIRECT RANK MODEL\n",
    "# 1e-6\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from model.roi_model import *\n",
    "\n",
    "# final_model = get_direct_rank_criteo_model()\n",
    "# final_model.compile(loss=None, optimizer='adam')\n",
    "#lambda y_true,y_pred: y_pred\n",
    "# print('trainable_weights')\n",
    "# for x in final_model.trainable_weights:\n",
    "#     print(x.name)\n",
    "# print('non_trainable_weights')\n",
    "# for x in final_model.non_trainable_weights:\n",
    "#     print(x.name)\n",
    "# final_model.summary()\n",
    "\n",
    "\n",
    "for i in range(count):\n",
    "\n",
    "    \n",
    "    \n",
    "    final_model = get_direct_rank_model()\n",
    "    final_model.compile(loss=None, optimizer='adam')\n",
    "\n",
    "    mcp_save = ModelCheckpoint('../model_file/roi/criteo/final_model/direct_rank/a_direct_rank_criteo_model_{}.h5'.format(i+1), save_best_only=False, monitor='val_loss', mode='min', save_weights_only=True)\n",
    "    history = final_model.fit([X_train, T_train, Y_conv_train, Y_visit_train], validation_split=0.2, epochs=109, batch_size=100000, shuffle=True, verbose=1, callbacks=[mcp_save, early_stopping])\n",
    "\n",
    "    \n",
    "    # plot_loss(history, \"loss\", \"val_loss\", \"obj\", \"val_obj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a19cce-248a-406a-96fb-e5c8c7a7bc20",
   "metadata": {},
   "source": [
    "# Second, on the calibration set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd3a25-5f42-4b9f-ba38-f83636a60b5e",
   "metadata": {},
   "source": [
    "### (i) Infer DR model to obtain $\\hat{roi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25db587d-e5af-4f80-a6b4-021b99d92d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "sys.path.append(\"..\")\n",
    "from model.roi_model import *\n",
    "\n",
    "count = 20\n",
    "\n",
    "DRP_aucc_cali_list = []\n",
    "roi_rank_pre_cali_list = []\n",
    "for i in range(count):\n",
    "    \n",
    "    \n",
    "    \n",
    "    final_model = get_direct_rank_model()\n",
    "    final_model.load_weights('../model_file/roi/criteo/final_model/direct_rank/a_direct_rank_criteo_model_{}.h5'.format(i+1, sample))\n",
    "\n",
    "    \n",
    "    roi_rank_pre_cali = final_model.predict([X_cali, T_cali, Y_conv_cali, Y_visit_cali])\n",
    "    DRP_aucc = get_uplift_model_aucc_no_show(t=(T_cali > 0.5).flatten(), y_reward=Y_conv_cali.flatten(), y_cost=Y_visit_cali.flatten(), roi_pred=roi_rank_pre_cali.flatten(), quantile=200)\n",
    "    roi_rank_pre_cali_list.append(roi_rank_pre_cali)\n",
    "    DRP_aucc_cali_list.append(DRP_aucc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284cd2b-4200-48b5-89c6-05fa692959e2",
   "metadata": {},
   "source": [
    "### (ii) Infer DR's MC Dropout model to obtain $\\hat{r}(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07ac30fa-88d9-43f3-99fd-a5ae34e34f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration =  1\n",
      "0\n",
      "cali\n",
      "4557/4557 [==============================] - 16s 3ms/step\n",
      "AUCC =  0.6052790809562676\n",
      "1\n",
      "cali\n",
      "4557/4557 [==============================] - 15s 3ms/step\n",
      "AUCC =  0.6019441157055129\n",
      "2\n",
      "cali\n",
      "4557/4557 [==============================] - 15s 3ms/step\n",
      "AUCC =  0.6011892978919282\n",
      "3\n",
      "cali\n",
      "4557/4557 [==============================] - 15s 3ms/step\n",
      "AUCC =  0.5981207130972329\n",
      "4\n",
      "cali\n",
      "4557/4557 [==============================] - 15s 3ms/step\n",
      "AUCC =  0.6083318617710375\n",
      "5\n",
      "cali\n",
      "4557/4557 [==============================] - 15s 3ms/step\n",
      "AUCC =  0.6036507241536772\n",
      "6\n",
      "cali\n",
      "4557/4557 [==============================] - 15s 3ms/step\n",
      "AUCC =  0.614030637675208\n",
      "7\n",
      "cali\n",
      "4557/4557 [==============================] - 15s 3ms/step\n",
      "AUCC =  0.6040788471818993\n",
      "8\n",
      "cali\n",
      "4557/4557 [==============================] - 15s 3ms/step\n",
      "AUCC =  0.5987572066257325\n",
      "9\n",
      "cali\n",
      "4557/4557 [==============================] - 15s 3ms/step\n",
      "AUCC =  0.603883973337891\n",
      "\n",
      "\n",
      "CPU times: user 3min 48s, sys: 28.2 s, total: 4min 16s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "DRP_aucc_cali_mc_list = []\n",
    "\n",
    "for i in range(count):\n",
    "    \n",
    "    print(\"iteration = \", i + 1)\n",
    "    \n",
    "    final_model = get_direct_rank_model_with_dropout()\n",
    "    final_model.load_weights('../model_file/roi/criteo/final_model/direct_rank/a_direct_rank_criteo_model_{}.h5'.format(i+1, sample))\n",
    "\n",
    "    # multiple prediction\n",
    "    n_iterations = 10\n",
    "    all_predictions_cali = []\n",
    "    \n",
    "    for j in range(n_iterations):\n",
    "        print(j)\n",
    "        \n",
    "        print(\"cali\")\n",
    "        predictions = final_model.predict([X_cali, T_cali, Y_conv_cali, Y_visit_cali])\n",
    "        all_predictions_cali.append(predictions)\n",
    "        DRP_aucc = get_uplift_model_aucc_no_show(t=(T_cali > 0.5).flatten(), y_reward=Y_conv_cali.flatten(), y_cost=Y_visit_cali.flatten(), roi_pred=predictions.flatten(), quantile=200)\n",
    "        DRP_aucc_cali_list.append(DRP_aucc[0])\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "# obtain mean and std\n",
    "mean_pred = np.mean(all_predictions_cali, axis=0)\n",
    "std_pred = np.std(all_predictions_cali, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2375d8c-26b5-4a6d-9ee4-b6e6dc661259",
   "metadata": {},
   "source": [
    "### (iii) Select $\\widetilde{roi}$'s equation form from 5a to 5c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64d0e456-2cb1-4742-a4ff-f8cd4edd460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCC =  0.6681109338530776\n"
     ]
    }
   ],
   "source": [
    "ROI_1 = roi_rank_pre_cali*(4.666666*roi_rank_pre_cali + std_pred) # AUCC \n",
    "ROI_2 = roi_rank_pre_cali/(std_pred + 1e5)\n",
    "ROI_3 = (3.9997*roi_rank_pre_cali + std_pred) #\n",
    "DRP_aucc_cali = get_uplift_model_aucc_no_show(t=(T_cali > 0.5).flatten(), y_reward=Y_conv_cali.flatten(), y_cost=Y_visit_cali.flatten(), roi_pred=ROI_3.flatten(), quantile=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fadec16-d9e2-46a5-828c-ef1e28173b1b",
   "metadata": {},
   "source": [
    "# Third, on the test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f233062-4bbe-4a6e-a409-9bb53bf33de6",
   "metadata": {},
   "source": [
    "### (i) Infer DR model to obtain $\\hat{roi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb132cad-2bb9-414b-8e14-a1f86c696b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.6067\n",
      "std = 0.0081\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import sklearn.metrics\n",
    "from metric.Metric import *\n",
    "\n",
    "count = 20\n",
    "\n",
    "\n",
    "DRP_aucc_test_list = []\n",
    "roi_rank_pre_test_list = []\n",
    "for i in range(count):\n",
    "   \n",
    "    final_model = get_direct_rank_model()\n",
    "    final_model.load_weights('../model_file/roi/criteo/final_model/direct_rank/a_direct_rank_criteo_model_{}.h5'.format(i+1, sample))\n",
    "\n",
    "\n",
    "    roi_rank_pre_test = final_model.predict([X_test, T_test, Y_conv_test, Y_visit_test])\n",
    "    roi_rank_pre_test_list.append(roi_rank_pre_test)\n",
    "    DRP_aucc = get_uplift_model_aucc_no_show(t=(T_test > 0.5).flatten(), y_reward=Y_conv_test.flatten(), y_cost=Y_visit_test.flatten(), roi_pred=roi_rank_pre_test.flatten(), quantile=200)\n",
    "    DRP_aucc_test_list.append(DRP_aucc)\n",
    "    \n",
    "mean_pred = np.mean(rDRP_aucc_test_list, axis=0)\n",
    "std_pred = np.std(rDRP_aucc_test_list, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"mean = {mean_pred:.4f}\")\n",
    "print(f\"std = {std_pred:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ae3c129-c2a1-4830-95f2-5838be98e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aucc =  0.6067944640917757\n"
     ]
    }
   ],
   "source": [
    "# store test aucc for pic \n",
    "import pandas as pd\n",
    "\n",
    "def get_aucc_cost_curve(aucc_list):\n",
    "    delta_cost_list_group = np.array([aucc[1] for aucc in aucc_list])\n",
    "    delta_reward_list_group = np.array([aucc[2] for aucc in aucc_list])\n",
    "    \n",
    "    avg_delta_cost_list = np.mean(delta_cost_list_group, axis=0)\n",
    "    avg_delta_reward_list = np.mean(delta_reward_list_group, axis=0)\n",
    "    \n",
    "    df_aucc_cost_curve = pd.DataFrame(avg_delta_cost_list, columns=['delta_cost'])\n",
    "    df_aucc_cost_curve['delta_reward'] = avg_delta_reward_list\n",
    "    \n",
    "    return df_aucc_cost_curve\n",
    "\n",
    "DRP_avg_aucc_cost_curve = get_aucc_cost_curve(DRP_aucc_test_list)\n",
    "print(\"aucc = \", np.sum(DRP_avg_aucc_cost_curve['delta_reward'].values) / (DRP_avg_aucc_cost_curve['delta_reward'].values[-1] * 201))\n",
    "DRP_avg_aucc_cost_curve.to_csv(\"../figure/mt/a_DR_avg_aucc_cost_curve_1.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4520caeb-5944-4aa2-bbff-824a9b3a519b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
